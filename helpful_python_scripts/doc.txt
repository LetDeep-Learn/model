ğŸ–¼ï¸ Image2Sketch GAN

This project converts real photos â†’ clean pencil-style sketches using a U-Net Generator + PatchGAN Discriminator (Pix2Pix-style).

The model is trained on paired datasets of photos and sketches.

ğŸ“Œ Project Overview

Goal: Take a normal photo as input â†’ generate a sketch-like output.

Model type: Conditional GAN (Pix2Pix framework).

Generator: U-Net (Encoder-Decoder with skip connections).

Discriminator: PatchGAN (judges local regions of the image).

âš™ï¸ How It Works
1. Generator (U-Net)

Encoder compresses the photo into features.

Decoder reconstructs features into a sketch.

Skip connections pass fine details directly (preserve edges).

2. Discriminator (PatchGAN)

Splits image into small patches (e.g., 70Ã—70).

Judges each patch â†’ real or fake sketch.

Helps Generator make sharper, realistic results.

ğŸ—‚ï¸ Project Structure
image2sketch/
â”‚â”€â”€ data/               # Training dataset (photo-sketch pairs)
â”‚â”€â”€ models/             # Generator + Discriminator architectures
â”‚â”€â”€ train.py            # Training script
â”‚â”€â”€ inference.py        # Generate sketch from new photos
â”‚â”€â”€ utils.py            # Helper functions (normalization, saving images, etc.)
â”‚â”€â”€ saved_models/       # Checkpoints (.pth files for generator & discriminator)
â”‚â”€â”€ README.md           # Project documentation

ğŸ“ Data Flow Diagram (DFD)

Hereâ€™s a simple DFD-style breakdown:

[ Input Photo ] 
       â”‚
       â–¼
+------------------+
|   U-Net Encoder  |   â† Extracts features (edges, textures)
+------------------+
       â”‚
       â–¼
+------------------+
|   U-Net Decoder  |   â† Rebuilds sketch with details
+------------------+
       â”‚
       â–¼
[ Generated Sketch ] ---------------------+
                                          â”‚
                                    +-----------+
                                    | PatchGAN  |
[ Real Sketch ] ------------------> |           |
                                    | Discriminator |
                                    +-----------+
                                          â”‚
                                Decides Real / Fake


ğŸ“ Explanation:

Generator (U-Net) makes a sketch.

Discriminator (PatchGAN) compares it with real sketches â†’ gives feedback.

During inference â†’ we only use the Generator.

ğŸš€ Training

Prepare dataset (photo-sketch pairs).

Run training script:

python train.py


Checkpoints will be saved in saved_models/.

ğŸ¨ Inference (Testing)

Use trained generator to create sketches from new photos:

python inference.py --input path/to/photo.jpg --output path/to/sketch.jpg


Only the generator weights are needed at this stage.

ğŸ”‘ Key Notes

Learning Rate: Start with 2e-4.

If loss stagnates â†’ decrease (e.g., 1e-4).

If training unstable â†’ decrease too.

Saved Weights: Only U-Net Generator is used for inference.

Discriminator: Only helps during training, not needed later.

